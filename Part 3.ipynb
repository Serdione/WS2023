{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559eb682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Необходимые импорты\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, BayesianRidge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, max_error\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14bdd18a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m      2\u001b[0m df \u001b[38;5;66;03m#k = columns/3\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#Визуальная оценка датасета\n",
    "df = pd.read_csv('dataset2.csv') \n",
    "df #k = columns/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbcd1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор признаков для классификации и регрессии\n",
    "Y_cls = df['IHD']\n",
    "X_cls = df.drop(columns = ['IHD', 'SL'])\n",
    "Y_reg = df['SL']\n",
    "X_reg = df.drop(columns = ['IHD', 'SL'])\n",
    "\n",
    "# 20 признаков для классификации\n",
    "selector_cls = SelectKBest(chi2, k = n)\n",
    "X_new = selector_cls.fit_transform(X_cls*1, Y_cls)\n",
    "features_cls = X_cls.columns[selector_cls.get_support()]\n",
    "print(features_cls)\n",
    "\n",
    "# 20 признаков для регрессии\n",
    "selector_reg = SelectKBest(f_regression, k = n)\n",
    "X_new = selector_reg.fit_transform(X_reg*1, Y_reg)\n",
    "features_reg = X_reg.columns[selector_reg.get_support()]\n",
    "print(features_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3903f81a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'selector_cls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Вывод графика выбранных признаковКрасным показаны значения p-values для 13 признаков, которые мы выбрали\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Синим выделены признаки, которые мы не выбираем\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mselector_cls\u001b[49m\u001b[38;5;241m.\u001b[39mget_support()\n\u001b[0;32m      5\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog10(selector_cls\u001b[38;5;241m.\u001b[39mpvalues_)\n\u001b[0;32m      6\u001b[0m X_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(X_cls\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'selector_cls' is not defined"
     ]
    }
   ],
   "source": [
    "# Вывод графика выбранных признаков для классификации\n",
    "# Красным показаны значения p-values для 13 признаков, которые мы выбрали\n",
    "# Синим выделены признаки, которые мы не выбираем\n",
    "\n",
    "mask = selector_cls.get_support()\n",
    "scores = -np.log10(selector_cls.pvalues_)\n",
    "X_indices = np.arange(X_cls.shape[-1])\n",
    "plt.figure(1, figsize=[15, 7])\n",
    "plt.clf()\n",
    "plt.bar(X_indices[mask], scores[mask] ** 0.5, width=0.2, color = 'red')\n",
    "plt.bar(X_indices[~mask], scores[~mask] ** 0.5, width=0.2, color = 'blue')\n",
    "plt.show()\n",
    "X_cls = X_cls.loc[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bc44b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вывод графика выбранных признаков для регрессии\n",
    "mask = selector_reg.get_support()\n",
    "scores = -np.log10(selector_reg.pvalues_)\n",
    "X_indices = np.arange(X_reg.shape[-1])\n",
    "plt.figure(1, figsize=[15, 7])\n",
    "plt.clf()\n",
    "plt.bar(X_indices[mask], scores[mask] ** 0.5, width=0.2, color = 'red')\n",
    "plt.bar(X_indices[~mask], scores[~mask] ** 0.5, width=0.2, color = 'blue')\n",
    "plt.show()\n",
    "X_reg = X_reg.loc[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6213c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA-анализ или уменьшение размерности для классификации\n",
    "X = X_cls.to_numpy()\n",
    "X = X.astype(float)\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "X_centered = X\n",
    "X_centered = (X - X.mean(axis=0)) / np.std(X, axis=0)\n",
    "pca.fit(X_centered)\n",
    "X_pca = pca.transform(X_centered)\n",
    "# p - признак, по которому выводим цвет, синий - ближе к минимальному значению, красный - к максимальному\n",
    "p = 0\n",
    "figure, axis = plt.subplots(1, 1)\n",
    "figure.set_size_inches(10, 10)\n",
    "axis.scatter(X_pca[:, 0], X_pca[:, 1], s=10, c=(X[:, p] - np.min(X[:, p])) /  (np.max(X[:, p])- np.min(X[:, p])), cmap='jet')\n",
    "plt.show()\n",
    "\n",
    "for i, component in enumerate(pca.components_):\n",
    "    print(\"{} component: {}% of initial variance\".format(i + 1, round(100 * pca.explained_variance_ratio_[i], 2)))\n",
    "    print(\" + \".join(\"%.3f x %s\" % (value, name) for value, name in zip(component, X_cls.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0523b46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вывод графика после уменьшения размерности\n",
    "p = 0\n",
    "figure, axis = plt.subplots(1, 1)\n",
    "figure.set_size_inches(10, 10)\n",
    "axis.scatter(X_pca[:, 0], X_pca[:, 1], s = 10 + 50*Y_cls, c =(X[:, p] - np.min(X[:, p])) /  (np.max(X[:, p])- np.min(X[:, p])), cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ffbe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вывод матрицы корреляций после уменьшения размерности\n",
    "X_cls_corr = X_cls.corr()\n",
    "fig, ax = plt.subplots(figsize=(15, 10)) \n",
    "sns.heatmap(X_cls_corr, ax=ax, xticklabels=True, yticklabels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2437117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA-анализ или уменьшение размерности для регрессии\n",
    "X = X_reg.to_numpy()\n",
    "X = X.astype(float)\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "X_centered = X\n",
    "X_centered = (X - X.mean(axis=0)) / np.std(X, axis=0)\n",
    "pca.fit(X_centered)\n",
    "X_pca = pca.transform(X_centered)\n",
    "# p - признак, по которому выводим цвет, синий - ближе к минимальному значению, красный - к максимальному\n",
    "p = 0\n",
    "figure, axis = plt.subplots(1, 1)\n",
    "figure.set_size_inches(10, 10)\n",
    "axis.scatter(X_pca[:, 0], X_pca[:, 1], s=10, c=(X[:, p] - np.min(X[:, p])) /  (np.max(X[:, p])- np.min(X[:, p])), cmap='jet')\n",
    "plt.show()\n",
    "\n",
    "for i, component in enumerate(pca.components_):\n",
    "    print(\"{} component: {}% of initial variance\".format(i + 1, round(100 * pca.explained_variance_ratio_[i], 2)))\n",
    "    print(\" + \".join(\"%.3f x %s\" % (value, name) for value, name in zip(component, X_reg.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e1cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вывод графика после уменьшения размерности\n",
    "p = 0\n",
    "figure, axis = plt.subplots(1, 1)\n",
    "figure.set_size_inches(10, 10)\n",
    "temp = Y_reg.copy()\n",
    "temp[temp == -1] = float(\"+inf\")\n",
    "temp[temp < 2] = 2\n",
    "temp = 1 / np.log2(temp)\n",
    "indx = temp > 0.3\n",
    "axis.scatter(X_pca[indx, 0], X_pca[indx, 1], s = X[indx, p], c = temp[indx], cmap='copper')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44f6a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вывод матрицы корреляций после уменьшения размерности\n",
    "X_reg_corr = X_reg.corr()\n",
    "fig, ax = plt.subplots(figsize=(15, 10)) \n",
    "sns.heatmap(X_reg_corr, ax=ax, xticklabels=True, yticklabels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "629a53d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определение дисбаланса данных\n",
    "print([sum(Y_cls), len(Y_cls)]) \n",
    "# https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data\n",
    "print([sum(Y_reg==-1), sum(Y_reg==0), sum(Y_reg==1), sum((Y_reg>=0)*(Y_reg<=360)), sum(Y_reg>360), max(Y_reg), Y_reg.quantile(0.95), len(Y_reg)])\n",
    "plt.plot(Y_reg.sort_values().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a6894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = Y_reg.copy()\n",
    "temp[temp == -1] = float(\"+inf\")\n",
    "temp[temp < 2] = 2\n",
    "temp = 1 / np.log2(temp)\n",
    "Y_reg = temp\n",
    "plt.plot(Y_reg.sort_values().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1c562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx_1 = Y_cls == 1\n",
    "indx_0 = Y_cls == 0\n",
    "# Удаляем строчки с мажоритарным классом с вероятностью (1 - sum(Y_cls) / len(Y_cls))\n",
    "counter = 0\n",
    "for i in range(len(Y_cls)):\n",
    "    if indx_0[i] == True:\n",
    "        counter = counter + 1\n",
    "    if counter > 2741:\n",
    "        indx_0[i] = False\n",
    "\n",
    "X_train_cls1, X_test_cls1, y_train_cls1, y_test_cls1 = train_test_split(X_cls[indx_1], Y_cls[indx_1], test_size=0.1, random_state=1)\n",
    "X_train_cls1, X_val_cls1, y_train_cls1, y_val_cls1 = train_test_split(X_train_cls1, y_train_cls1, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train_cls0, X_test_cls0, y_train_cls0, y_test_cls0 = train_test_split(X_cls[indx_0], Y_cls[indx_0], test_size=0.24, random_state=1)\n",
    "X_train_cls0, X_val_cls0, y_train_cls0, y_val_cls0 = train_test_split(X_train_cls0, y_train_cls0, test_size=0.63, random_state=1)\n",
    "\n",
    "X_train_cls = pd.concat([X_train_cls0, X_train_cls1])\n",
    "y_train_cls = pd.concat([y_train_cls0, y_train_cls1])\n",
    "X_val_cls = pd.concat([X_val_cls0, X_val_cls1])\n",
    "y_val_cls = pd.concat([y_val_cls0, y_val_cls1])\n",
    "X_test_cls = pd.concat([X_test_cls0, X_test_cls1])\n",
    "y_test_cls = pd.concat([y_test_cls0, y_test_cls1])\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, Y_reg, test_size=0.1, random_state=1) # 0.2 тестовая выборка\n",
    "X_train_reg, X_val_reg, y_train_reg, y_val_reg = train_test_split(X_train_reg, y_train_reg, test_size=0.2, random_state=1) # 0.2*0.8 = 0.18 валидационная, 0.72 обучающая"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбор модели прогнозирования и настройка гиперпараметров для регрессии\n",
    "names = [\n",
    "    \"LinearRegression\",\n",
    "    \"Ridge\",\n",
    "    \"BayesianRidge\",\n",
    "    \"PolynomialFeatures\",\n",
    "    \"SVR linear\",\n",
    "    \"SVR rbf\",\n",
    "    \"KNeighborsRegressor\",\n",
    "    \"GaussianProcessRegressor\",\n",
    "    \"DecisionTreeRegressor\",\n",
    "    \"RandomForestRegressor\",\n",
    "    \"MLPRegressor\",\n",
    "]\n",
    "\n",
    "regressors = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0, solver='auto'),\n",
    "    BayesianRidge(),\n",
    "    Pipeline([('poly', PolynomialFeatures(degree=2)), ('linear', LinearRegression(fit_intercept=False))]),\n",
    "    SVR(kernel='linear'),\n",
    "    SVR(kernel='rbf'),\n",
    "    KNeighborsRegressor(3),\n",
    "    GaussianProcessRegressor(kernel=DotProduct() + WhiteKernel()),\n",
    "    DecisionTreeRegressor(max_depth=5),\n",
    "    RandomForestRegressor(max_depth=5, n_estimators=10, max_features=2),\n",
    "    MLPRegressor(alpha=1, max_iter=1000),\n",
    "]\n",
    "\n",
    "for name, rgr in zip(names, regressors):\n",
    "    rgr.fit(X_train_reg, y_train_reg)\n",
    "    pred_reg = rgr.predict(X_val_reg)\n",
    "    score = mean_squared_error(y_val_reg, pred_reg)\n",
    "    print(name, score)\n",
    "    \n",
    "# Пороговое значение MSE, когда в качестве y выбираем среднее значение по y\n",
    "np.mean((np.mean(y_val_reg)-y_val_reg) **2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e96f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выбираем следующие модели для подбора гиперпараметров: LinearRegression (без настройки) \n",
    "#BayesianRidge KNeighborsRegressor DecisionTreeRegressor RandomForestRegressor MLPRegressor\n",
    "parameters = {'max_depth':[13], 'n_estimators':[200], 'max_features': ['sqrt']}\n",
    "\n",
    "rgr = GridSearchCV(estimator=RandomForestRegressor(), param_grid=parameters, scoring='neg_mean_squared_error')\n",
    "rgr.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "results = pd.DataFrame.from_dict(rgr.cv_results_)\n",
    "results = results.sort_values('rank_test_score', ignore_index=True)\n",
    "print(results['params'][0])\n",
    "pred_reg = rgr.predict(X_val_reg)\n",
    "\n",
    "print(mean_squared_error(y_val_reg, pred_reg))\n",
    "print(r2_score(y_val_reg, pred_reg))\n",
    "print(mean_absolute_error(y_val_reg, pred_reg))\n",
    "print(max_error(y_val_reg, pred_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_neighbors':[15, 25, 50], 'weights':['uniform', 'distance'], 'p':[1, 2]}\n",
    "\n",
    "rgr = GridSearchCV(estimator=KNeighborsRegressor(), param_grid=parameters, scoring='neg_mean_squared_error')\n",
    "rgr.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "results = pd.DataFrame.from_dict(rgr.cv_results_)\n",
    "results = results.sort_values('rank_test_score', ignore_index=True)\n",
    "print(results['params'][0])\n",
    "pred_reg = rgr.predict(X_val_reg)\n",
    "\n",
    "print(mean_squared_error(y_val_reg, pred_reg))\n",
    "print(r2_score(y_val_reg, pred_reg))\n",
    "print(mean_absolute_error(y_val_reg, pred_reg))\n",
    "print(max_error(y_val_reg, pred_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d37163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_iter':[500], 'tol':[1e-4], 'alpha_1':[1e-5, 1e-6, 1e-7], 'alpha_2':[1e-5, 1e-6, 1e-7]}\n",
    "\n",
    "rgr = GridSearchCV(estimator=BayesianRidge(), param_grid=parameters, scoring='neg_mean_squared_error')\n",
    "rgr.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "results = pd.DataFrame.from_dict(rgr.cv_results_)\n",
    "results = results.sort_values('rank_test_score', ignore_index=True)\n",
    "print(results['params'][0])\n",
    "pred_reg = rgr.predict(X_val_reg)\n",
    "\n",
    "print(mean_squared_error(y_val_reg, pred_reg))\n",
    "print(r2_score(y_val_reg, pred_reg))\n",
    "print(mean_absolute_error(y_val_reg, pred_reg))\n",
    "print(max_error(y_val_reg, pred_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a447f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'hidden_layer_sizes':[(20, ), (50, ), (100, )], 'activation':['relu', 'logistic'], 'solver':['adam', 'lbfgs']}\n",
    "\n",
    "rgr = GridSearchCV(estimator=MLPRegressor(), param_grid=parameters, scoring='neg_mean_squared_error')\n",
    "rgr.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "results = pd.DataFrame.from_dict(rgr.cv_results_)\n",
    "results = results.sort_values('rank_test_score', ignore_index=True)\n",
    "print(results['params'][0])\n",
    "pred_reg = rgr.predict(X_val_reg)\n",
    "\n",
    "print(mean_squared_error(y_val_reg, pred_reg))\n",
    "print(r2_score(y_val_reg, pred_reg))\n",
    "print(mean_absolute_error(y_val_reg, pred_reg))\n",
    "print(max_error(y_val_reg, pred_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21a8616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
